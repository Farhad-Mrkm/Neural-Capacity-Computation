# -*- coding: utf-8 -*-
"""NAAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VfRM5uZ47UB-St-OoaFuibkBk91uF8jv
"""

class PeakConstraint(nn.Module):
  """Implements an activation for peak constraint """
  def __init__(self, peak, **extra_kwargs):
    super(PeakConstraint, self).__init__()
    self.peak_activation = nn.Threshold(-peak, -peak)
  def forward(self, x):
    x = self.peak_activation(x)
    neg1 = torch.tensor(-1.0)
    x = neg1 * x
    x = self.peak_activation(x)
    x = neg1 * x
    return x


class NIT(nn.Module):
  """NIT """
  def __init__(self, dim, hidden_dim, layers, activation, avg_P, peak=None,positive=None, **extra_kwargs):
    super(NIT, self).__init__()
    self._f = mlp(dim, hidden_dim, dim, layers, activation)
    self.avg_P = torch.tensor(avg_P)  # average power constraint
    self.peak = peak  # peak constraint  
    self.positive=positive
    self.ps=F.softplus
    if self.peak is not None:
      print('here')
      self.peak_activation = PeakConstraint(peak)
  
  def forward(self, x):
    batch_size = x.size(0)
    unnorm_tx = self._f(x)

    norm_tx = unnorm_tx/torch.sqrt(torch.mean(torch.pow(unnorm_tx,2.0)))*torch.sqrt(self.avg_P)

    if self.peak is not None:
      norm_tx = self.peak_activation(norm_tx)
    if self.positive is not None:
      norm_tx=self.ps(norm_tx)

    return norm_tx

class AWGN_Chan(nn.Module):
  """AWGN Channel """
  def __init__(self, stdev=1.0):
    super(AWGN_Chan, self).__init__()
    self.stdev = torch.tensor(stdev)

  def forward(self, x):
    noise = torch.randn_like(x) * self.stdev
    return x + noise