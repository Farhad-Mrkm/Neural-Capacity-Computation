# -*- coding: utf-8 -*-
"""Train_MI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oFuRKHkp-t8C4YeI_VKHZGMFV3d7Vcpb
"""



def train_estimator(critic_params, data_params, opt_params, device, 
                    critic_type, **kwargs):
    """Main training loop that estimates time-varying MI."""
    
    if critic_type=='concat':
        critic = ConcatCritic(critic_params['dim'], critic_params['hidden_dim'],
                              critic_params['layers'], critic_params['activation'])
    elif critic_type=='ent_concat':
        critic = ConcatEntropicCritic(critic_params['dim'], critic_params['hidden_dim'],
                              critic_params['layers'], critic_params['activation'],
                              device, critic_params['ref_batch_factor'])
    elif critic_type=='chi_square':
        critic=chiCritic(critic_params['dim'], critic_params['hidden_dim'],
                              critic_params['layers'], critic_params['activation'],
                              device, critic_params['ref_batch_factor'])
    else:
        critic = SeparableCritic(critic_params['dim'], critic_params['hidden_dim'], critic_params['embed_dim'],
                              critic_params['layers'], critic_params['activation'])

    critic.to(device)
    if critic_type=='ent_concat':
      opt_ent_xy = torch.optim.Adam(critic.fxy.parameters(), lr=opt_params['learning_rate'])
      opt_ent_x = torch.optim.Adam(critic.fx.parameters(), lr=opt_params['learning_rate'])
      opt_ent_y = torch.optim.Adam(critic.fy.parameters(), lr=opt_params['learning_rate'])

    elif critic_type=='chi_square':
        opt_crit = torch.optim.Adam(critic.fxy.parameters(), lr=opt_params['learning_rate'])
    else:
        opt_crit = torch.optim.Adam(critic.parameters(), lr=opt_params['learning_rate'])
    x_samplei, y_samplei = awgn_chan(100000, data_params['tx_power'], data_params['noise_power'])
    if data_params['tx_power']<=np.power(10,30/10):
        bins1=1000
    else:
        bins1=7000
    dens_ref = _uniform_sampling(x_samplei, 100000)
    dens_ref1 = _uniform_sampling(y_samplei, 100000)
    dens_x_sample = np.histogram(x_samplei, bins1)  # ,np.min(dens_ref),np.max(dens_ref))
    dens_y_sample = np.histogram(y_samplei, bins1)  # ,np.min(dens_ref1),np.max(dens_ref1))
    histrefx=np.histogram(dens_ref,bins1)
    histrefy=np.histogram(dens_ref1,bins1)
    numm=0
    numm1=0
    numm2=0
    numm3=0
    for counter1 in range(bins1):
        if histrefx[0][counter1]!=0:
            numm=numm+((dens_x_sample[0][counter1]/1000000-histrefx[0][counter1]/100000)**2)/(histrefx[0][counter1]/100000)

    for counter2 in range(bins1):
        if dens_x_sample[0][counter2]!=0:
            numm1=numm1+((dens_x_sample[0][counter2]/1000000-histrefx[0][counter2]/100000)**2)/(dens_x_sample[0][counter2]/1000000) 
    for counter3 in range(bins1):
        if histrefy[0][counter3]!=0:
            numm2=numm2+((dens_y_sample[0][counter3]/1000000-histrefy[0][counter3]/100000)**2)/(histrefy[0][counter3]/100000) 
    for counter4 in range(bins1):
        if dens_y_sample[0][counter1]!=0:
            numm3=numm3+((dens_y_sample[0][counter4]/1000000-histrefy[0][counter4]/100000)**2)/(dens_y_sample[0][counter4]/1000000)    

    chi2x=np.log10(2)*numm 
    chi2xrev=np.log10(2)*numm1
    chi2y=np.log10(2)*numm2
    chi2yrev=np.log10(2)*numm3
    chi2xright=(1.5*(chi2x)**2)*np.log2(np.exp(1))
    chi2xleft=((1+chi2xrev)*(1+chi2x)**2)-1
    chi2yright=(1.5*(chi2y)**2)*np.log2(np.exp(1))
    chi2yleft=((1+chi2yrev)*(1+chi2y)**2)-1
    if data_params['tx_power']<=np.power(10,50/10):
        upkl_x = np.log2(np.exp(1))*np.log2(1+chi2x)- np.log2(np.exp(1))*(chi2xright/chi2xleft)   
        upkl_y =np.log2(np.exp(1))*np.log2(1+chi2y)- np.log2(np.exp(1))*(chi2yright/chi2yleft)
        upkl_x = torch.tensor(upkl_x, dtype=torch.float)
        upkl_y = torch.tensor(upkl_y, dtype=torch.float)
    else:
        upkl_x = torch.tensor(0., dtype=torch.float)
        upkl_y = torch.tensor(0., dtype=torch.float)

    def train_step(data_params, opt_params, critic_type='ent_concat'):
        # Annoying special case:
        # For the true conditional, the critic depends on the true correlation rho,
        # so we rebuild the critic at each iteration.
        x, y = awgn_chan(data_params['batch_size'], data_params['tx_power'], data_params['noise_power'])
        if critic_type=='concat':
          opt_crit.zero_grad()
          mi = estimate_mutual_information(opt_params['estimator'], x, y, critic, device, 
                                           critic_type, **kwargs)
          loss = -mi
          loss.backward()
          torch.nn.utils.clip_grad_norm_(critic.parameters(), 2)
          opt_crit.step()
        elif critic_type=='chi_square':
            opt_crit.zero_grad()
            mi = estimate_mutual_information(opt_params['estimator'], x, y, critic, device, 
                                           critic_type, **kwargs)
            loss = -mi
            loss.backward()
            #torch.nn.utils.clip_grad_norm_(critic.fxy.parameters(), 2)
            opt_crit.step()
        else:
          opt_ent_xy.zero_grad()
          opt_ent_x.zero_grad()
          opt_ent_y.zero_grad()
          d_xy, d_x, d_y = estimate_mutual_information(opt_params['estimator'], x, y, critic, device, 
                                                      critic_type, **kwargs)
          loss_xy = -d_xy
          loss_x = -d_x
          loss_y = -d_y
          loss_xy.backward()
          torch.nn.utils.clip_grad_norm_(critic.fxy.parameters(), 2)
          opt_ent_xy.step()
          loss_x.backward()
          torch.nn.utils.clip_grad_norm_(critic.fx.parameters(), 2)
          opt_ent_x.step()
          loss_y.backward()
          torch.nn.utils.clip_grad_norm_(critic.fy.parameters(), 2)
          opt_ent_y.step()
          mi = d_xy - d_x - d_y
        if critic_type!='chi_square':
            return mi
        else:
            return mi-upkl_x-upkl_y



    estimates = []
    for i in tqdm(range(opt_params['iterations'])):
        mi = train_step(data_params, opt_params, critic_type=critic_type)
        mi = mi.detach().cpu().numpy()
        estimates.append(mi)

    return np.array(estimates)